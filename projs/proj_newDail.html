<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>快点标签小心得</title>
    <link rel="icon" href="favicon.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" href="/stylesheets/normalize.css">
    <link rel="stylesheet" href="/stylesheets/font-awesome.min.css">
    <link rel="stylesheet" href="/stylesheets/styles_v2.0.css">
  </head>
  <body>
    <section class="blogV2-wrapper">
      <header id="blogV2-head">
        <h1><a href="https://github.com/kmokidd" title="go to kmokidd's github">@kmokidd</a></h1>
          <ul id="blogV2-nav">
            <li class="on"><a href="/index.html">Archives</a></li>
            <li><a href="">Projects-ing</a></li>
            <li><a href="/aboutMe.html">About</a></li>
            <li><a href="">Contact</a></li>
          </ul>
      </header>
      <nav id="blogV2-archives-nav">
        <a href="/summary/winter-intern-2014.html" class="prev"><i class="icon icon-circle-arrow-left"></i>Prev/前篇</a>
        <a href="/study/nodeJS.html" class="next">Next/后篇<i class="icon icon-circle-arrow-right"></i></a>
      </nav>
      <section id="archives-post">
        <h2 class="post-title">快点标签小心得
          <time class="push-time">2014/03/10</time>
        </h2>
        <article class="post-content">
          <p>与xlg合作的第一个项目，其实很悲催地在去年10月就已经说好的东西这会子已经半年过去了，还木有个成品出来我太羞愧了。所以这个大四下我就奉献给快点标签啦，如果有一天它在Chrome APP store上成为“+1人数最多的新标签页插件”，这篇博文就是来让人膜拜的哇哈哈哈。</p>
          <p>这两天是把一个网站的数据用python简单地爬了一下，用了urllib2写了两行的爬虫，再用正则做了一次数据的过滤。写小蜘蛛的时候是看了<a href="http://blog.csdn.net/column/details/why-bug.html">Python爬虫入门教程</a>，一个SDU的学生写的，我觉得写的很不错，（孩儿还这么小就这么厉害哎哎哎）。然后Python的正则内容比较简单，当然，这是相对于“正则表达式”这一整个概念来说的，我是看刚刚上面链接中的<a href="http://blog.csdn.net/pleasecallmewhy/article/details/8929576">Python中的正则表达式教程</a>，这个教程Google上一搜都是大同小异的东西。其实在写小爬虫的时候我并没有写好，才爬了5页多网站立马block了我，Error10056了，我爬的网站页数少就犯懒没有去解决= =，在上述链接的教程里有提供解决的方法</p>
          <pre>
import urllib2
import re

headers = {
  'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.117 Safari/537.36',
  'Referer':'http://www.alexa.com/topsites/countries'
}

fileHandle = open('website2.txt', 'a')
for i in range(0, 20): #这里是要去找url的规律，将url和页数联系在一起
  url = "http://www.domain.com"+i
  req = urllib2.Request(
      url = url,
      headers = headers)
  pageContent = urllib2.urlopen(req).read()
  result = re.findall(r'pattern', pageContent) #返回的是list 无法直接写入file

  for item in result: # 要一个个写入file
      fileHandle.write(item)
fileHandle.close()
          </pre>
          <p>另外今天看到一个练习git命令的网站，推荐给常常忘记git命令的人：<a href="http://try.github.io/levels/1/challenges/1">http://try.github.io/</a></p>
        </article>
      </section>
    </section>
  </body>
</html>